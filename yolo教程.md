yolo11è¶…è¯¦ç»†æ•™ç¨‹



### ä¸€ã€YOLO11ç®€ä»‹

[ultralytics](https://github.com/ultralytics/ultralytics)ï¼šæ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œé€šè¿‡å®ƒå¯ä»¥ä½¿ç”¨YOLO11æ¨¡å‹ï¼Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ°å½“å‰ç›®å½•ï¼ˆè‡ªå·±æ‰‹åŠ¨åœ¨æµè§ˆå™¨ä¸‹è½½è¦å¿«å¾ˆå¤šï¼‰ï¼Œæ”¯æŒYOLOv2åˆ°YOLO11ã€‚

YOLO11çš„æ¨¡å‹éƒ½ä¸å¤§ï¼Œ`yolo11n.pt` ä¸º5.4Mï¼Œ`yolo11x.pt` ä¸º109Mã€‚

ultralyticsæ–‡æ¡£ï¼šhttps://docs.ultralytics.com/

æ¨¡å‹ä¸‹è½½åœ°å€ï¼šhttps://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt

`ultralytics`ä¸º`YOLO11`åœ¨ä¸åŒåŠŸèƒ½ä¸Šè®­ç»ƒäº†ä¸€æ‰¹æ¨¡å‹ï¼Œç”±äºä¸åŒæ•°æ®é›†çš„ç‰¹ç‚¹ï¼Œæ‰€ä»¥é’ˆå¯¹ä¸åŒçš„åŠŸèƒ½ä¼šé€‰æ‹©åœ¨ä¸åŒæ•°æ®é›†ä¸Šè®­ç»ƒã€‚

YOLO11 [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/) and [Pose](https://docs.ultralytics.com/tasks/pose/) models pretrained on the [COCO](https://docs.ultralytics.com/datasets/detect/coco/) dataset are available here, as well as YOLO11 [Classify](https://docs.ultralytics.com/tasks/classify/) models pretrained on the [ImageNet](https://docs.ultralytics.com/datasets/classify/imagenet/) dataset. [Track](https://docs.ultralytics.com/modes/track/) mode is available for all Detect, Segment and Pose models. All [Models](https://docs.ultralytics.com/models/) download automatically from the latest Ultralytics [release](https://github.com/ultralytics/assets/releases) on first use.



**æ¨¡å‹æŒ‡æ ‡**

size (pixels)ï¼šå›¾ç‰‡åƒç´  640 * 640

mAPï¼šå¹³å‡ç²¾åº¦å‡å€¼

Speedï¼šæ¨ç†æ—¶é—´ï¼Œæ¯«ç§’

params (M)ï¼šå‚æ•°é‡ï¼Œç™¾ä¸‡çº§

FLOPs (G)ï¼šæ¯ç§’æµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚Gè¡¨ç¤º10äº¿ï¼Œå¯ä»¥ç”¨æ¥è¡¡é‡ç®—æ³•/æ¨¡å‹å¤æ‚åº¦ï¼Œç†è®ºä¸Šè¯¥æ•°å€¼è¶Šé«˜è¶Šå¥½



**æ¨¡å‹è§„æ ¼**

æ¨¡å‹åç¼€`n, s, m, l, x`ä»£è¡¨æ¨¡å‹è¶Šæ¥è¶Šå¤§ã€‚

YOLO11m åœ¨å‡†ç¡®æ€§ã€æ•ˆç‡ã€æ¨¡å‹å¤§å°ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡



**æ¨¡å‹åŠŸèƒ½**

- Detectï¼šç‰©ä½“æ£€æµ‹
- Segmentï¼šå›¾åƒåˆ†å‰²
- Classifyï¼šåˆ†ç±»
- Poseï¼šäººä½“å§¿æ€æ¨æ–­
- OBBï¼šå®šå‘ç‰©ä½“æ£€æµ‹ï¼Œæ£€æµ‹æ¡†æœ‰ä¸€å®šçš„å€¾æ–œè§’åº¦
- Trackï¼šç‰©ä½“è¿½è¸ª



![image-20250313105036683](D:\dev\php\magook\trunk\server\md\img\image-20250313105036683.png)



**æ¨¡å‹åˆ—è¡¨**

<details open><summary>Detection (COCO)</summary>

See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for usage examples with these models trained on [COCO](https://docs.ultralytics.com/datasets/detect/coco/), which include 80 pre-trained classes.

| Model                                                                                | size<br><sup>(pixels) | mAP<sup>val<br>50-95 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>T4 TensorRT10<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) |
| ------------------------------------------------------------------------------------ | --------------------- | -------------------- | ------------------------------ | ----------------------------------- | ------------------ | ----------------- |
| [YOLO11n](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt) | 640                   | 39.5                 | 56.1 Â± 0.8                     | 1.5 Â± 0.0                           | 2.6                | 6.5               |
| [YOLO11s](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt) | 640                   | 47.0                 | 90.0 Â± 1.2                     | 2.5 Â± 0.0                           | 9.4                | 21.5              |
| [YOLO11m](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt) | 640                   | 51.5                 | 183.2 Â± 2.0                    | 4.7 Â± 0.1                           | 20.1               | 68.0              |
| [YOLO11l](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt) | 640                   | 53.4                 | 238.6 Â± 1.4                    | 6.2 Â± 0.1                           | 25.3               | 86.9              |
| [YOLO11x](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt) | 640                   | 54.7                 | 462.8 Â± 6.7                    | 11.3 Â± 0.2                          | 56.9               | 194.9             |

- **mAP<sup>val</sup>** values are for single-model single-scale on [COCO val2017](https://cocodataset.org/) dataset. <br>Reproduce by `yolo val detect data=coco.yaml device=0`
- **Speed** averaged over COCO val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/) instance. <br>Reproduce by `yolo val detect data=coco.yaml batch=1 device=0|cpu`

</details>

<details><summary>Segmentation (COCO)</summary>

See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for usage examples with these models trained on [COCO-Seg](https://docs.ultralytics.com/datasets/segment/coco/), which include 80 pre-trained classes.

| Model                                                                                        | size<br><sup>(pixels) | mAP<sup>box<br>50-95 | mAP<sup>mask<br>50-95 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>T4 TensorRT10<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) |
| -------------------------------------------------------------------------------------------- | --------------------- | -------------------- | --------------------- | ------------------------------ | ----------------------------------- | ------------------ | ----------------- |
| [YOLO11n-seg](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt) | 640                   | 38.9                 | 32.0                  | 65.9 Â± 1.1                     | 1.8 Â± 0.0                           | 2.9                | 10.4              |
| [YOLO11s-seg](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-seg.pt) | 640                   | 46.6                 | 37.8                  | 117.6 Â± 4.9                    | 2.9 Â± 0.0                           | 10.1               | 35.5              |
| [YOLO11m-seg](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-seg.pt) | 640                   | 51.5                 | 41.5                  | 281.6 Â± 1.2                    | 6.3 Â± 0.1                           | 22.4               | 123.3             |
| [YOLO11l-seg](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-seg.pt) | 640                   | 53.4                 | 42.9                  | 344.2 Â± 3.2                    | 7.8 Â± 0.2                           | 27.6               | 142.2             |
| [YOLO11x-seg](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-seg.pt) | 640                   | 54.7                 | 43.8                  | 664.5 Â± 3.2                    | 15.8 Â± 0.7                          | 62.1               | 319.0             |

- **mAP<sup>val</sup>** values are for single-model single-scale on [COCO val2017](https://cocodataset.org/) dataset. <br>Reproduce by `yolo val segment data=coco.yaml device=0`
- **Speed** averaged over COCO val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/) instance. <br>Reproduce by `yolo val segment data=coco.yaml batch=1 device=0|cpu`

</details>

<details><summary>Classification (ImageNet)</summary>

See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for usage examples with these models trained on [ImageNet](https://docs.ultralytics.com/datasets/classify/imagenet/), which include 1000 pretrained classes.

| Model                                                                                        | size<br><sup>(pixels) | acc<br><sup>top1 | acc<br><sup>top5 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>T4 TensorRT10<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) at 224 |
| -------------------------------------------------------------------------------------------- | --------------------- | ---------------- | ---------------- | ------------------------------ | ----------------------------------- | ------------------ | ------------------------ |
| [YOLO11n-cls](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt) | 224                   | 70.0             | 89.4             | 5.0 Â± 0.3                      | 1.1 Â± 0.0                           | 1.6                | 0.5                      |
| [YOLO11s-cls](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-cls.pt) | 224                   | 75.4             | 92.7             | 7.9 Â± 0.2                      | 1.3 Â± 0.0                           | 5.5                | 1.6                      |
| [YOLO11m-cls](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-cls.pt) | 224                   | 77.3             | 93.9             | 17.2 Â± 0.4                     | 2.0 Â± 0.0                           | 10.4               | 5.0                      |
| [YOLO11l-cls](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-cls.pt) | 224                   | 78.3             | 94.3             | 23.2 Â± 0.3                     | 2.8 Â± 0.0                           | 12.9               | 6.2                      |
| [YOLO11x-cls](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-cls.pt) | 224                   | 79.5             | 94.9             | 41.4 Â± 0.9                     | 3.8 Â± 0.0                           | 28.4               | 13.7                     |

- **acc** values are model accuracies on the [ImageNet](https://www.image-net.org/) dataset validation set. <br>Reproduce by `yolo val classify data=path/to/ImageNet device=0`
- **Speed** averaged over ImageNet val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/) instance. <br>Reproduce by `yolo val classify data=path/to/ImageNet batch=1 device=0|cpu`

</details>

<details><summary>Pose (COCO)</summary>

See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for usage examples with these models trained on [COCO-Pose](https://docs.ultralytics.com/datasets/pose/coco/), which include 1 pre-trained class, person.

| Model                                                                                          | size<br><sup>(pixels) | mAP<sup>pose<br>50-95 | mAP<sup>pose<br>50 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>T4 TensorRT10<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) |
| ---------------------------------------------------------------------------------------------- | --------------------- | --------------------- | ------------------ | ------------------------------ | ----------------------------------- | ------------------ | ----------------- |
| [YOLO11n-pose](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt) | 640                   | 50.0                  | 81.0               | 52.4 Â± 0.5                     | 1.7 Â± 0.0                           | 2.9                | 7.6               |
| [YOLO11s-pose](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-pose.pt) | 640                   | 58.9                  | 86.3               | 90.5 Â± 0.6                     | 2.6 Â± 0.0                           | 9.9                | 23.2              |
| [YOLO11m-pose](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-pose.pt) | 640                   | 64.9                  | 89.4               | 187.3 Â± 0.8                    | 4.9 Â± 0.1                           | 20.9               | 71.7              |
| [YOLO11l-pose](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-pose.pt) | 640                   | 66.1                  | 89.9               | 247.7 Â± 1.1                    | 6.4 Â± 0.1                           | 26.2               | 90.7              |
| [YOLO11x-pose](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-pose.pt) | 640                   | 69.5                  | 91.1               | 488.0 Â± 13.9                   | 12.1 Â± 0.2                          | 58.8               | 203.3             |

- **mAP<sup>val</sup>** values are for single-model single-scale on [COCO Keypoints val2017](https://cocodataset.org/) dataset. <br>Reproduce by `yolo val pose data=coco-pose.yaml device=0`
- **Speed** averaged over COCO val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/) instance. <br>Reproduce by `yolo val pose data=coco-pose.yaml batch=1 device=0|cpu`

</details>

<details><summary>OBB (DOTAv1)</summary>

See [OBB Docs](https://docs.ultralytics.com/tasks/obb/) for usage examples with these models trained on [DOTAv1](https://docs.ultralytics.com/datasets/obb/dota-v2/#dota-v10/), which include 15 pre-trained classes.

| Model                                                                                        | size<br><sup>(pixels) | mAP<sup>test<br>50 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>T4 TensorRT10<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) |
| -------------------------------------------------------------------------------------------- | --------------------- | ------------------ | ------------------------------ | ----------------------------------- | ------------------ | ----------------- |
| [YOLO11n-obb](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-obb.pt) | 1024                  | 78.4               | 117.6 Â± 0.8                    | 4.4 Â± 0.0                           | 2.7                | 17.2              |
| [YOLO11s-obb](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-obb.pt) | 1024                  | 79.5               | 219.4 Â± 4.0                    | 5.1 Â± 0.0                           | 9.7                | 57.5              |
| [YOLO11m-obb](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-obb.pt) | 1024                  | 80.9               | 562.8 Â± 2.9                    | 10.1 Â± 0.4                          | 20.9               | 183.5             |
| [YOLO11l-obb](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-obb.pt) | 1024                  | 81.0               | 712.5 Â± 5.0                    | 13.5 Â± 0.6                          | 26.2               | 232.0             |
| [YOLO11x-obb](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-obb.pt) | 1024                  | 81.3               | 1408.6 Â± 7.7                   | 28.6 Â± 1.0                          | 58.8               | 520.2             |

- **mAP<sup>test</sup>** values are for single-model multiscale on [DOTAv1](https://captain-whu.github.io/DOTA/index.html) dataset. <br>Reproduce by `yolo val obb data=DOTAv1.yaml device=0 split=test` and submit merged results to [DOTA evaluation](https://captain-whu.github.io/DOTA/evaluation.html).
- **Speed** averaged over DOTAv1 val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/) instance. <br>Reproduce by `yolo val obb data=DOTAv1.yaml batch=1 device=0|cpu`

</details>



### äºŒã€ä½¿ç”¨YOLO11æ¨¡å‹

ç¯å¢ƒå‡†å¤‡

```bash
python >= 3.8
pytorch >= 1.8

conda create -n yolo11 python=3.11.4
conda activate yolo11
pip install ultralytics
```

åˆ›å»ºé¡¹ç›® `learn-yolo`

ä¸‹è½½ `ultralytics`ä»£ç ï¼Œå› ä¸ºæœ‰ä¸€äº›ä¸œè¥¿éœ€è¦å‚è€ƒï¼Œä¸»è¦æ˜¯`ultralytics`ç›®å½•ã€‚



#### 1ã€Detect

å‚è€ƒï¼šhttps://docs.ultralytics.com/tasks/detect/

ä»å›¾åƒæˆ–è§†é¢‘æµä¸­ï¼Œè¯†åˆ«å¯¹è±¡çš„ä½ç½®å’Œç±»åˆ«ã€‚

ç‰©ä½“æ£€æµ‹å™¨çš„è¾“å‡ºæ˜¯ä¸€ç»„åŒ…å›´å›¾åƒä¸­ç‰©ä½“çš„è¾¹æ¡†ï¼Œä»¥åŠæ¯ä¸ªè¾¹æ¡†çš„ç±»åˆ«æ ‡ç­¾å’Œç½®ä¿¡åº¦åˆ†æ•°ã€‚å¦‚æœæ‚¨éœ€è¦è¯†åˆ«åœºæ™¯ä¸­æ„Ÿå…´è¶£çš„ç‰©ä½“ï¼Œä½†åˆä¸éœ€è¦çŸ¥é“ç‰©ä½“çš„å…·ä½“ä½ç½®æˆ–ç¡®åˆ‡å½¢çŠ¶ï¼Œé‚£ä¹ˆç‰©ä½“æ£€æµ‹å°±æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚

Predictï¼šhttps://docs.ultralytics.com/modes/predict/

æˆ‘ä»¬çŸ¥é“ï¼ŒDetect åŠŸèƒ½æ˜¯åœ¨ COCO æ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œé‚£è¿™ä¸ª COCO æ•°æ®é›†å¯ä»¥è¯†åˆ«å“ªäº›ä¸œè¥¿å‘¢ã€‚æˆ‘ä»¬æ‰“å¼€`ultralytics/cfg/datasets/coco.yaml`æ–‡ä»¶ï¼Œé‡Œé¢åˆ—å‡ºäº† 80 ä¸ªç‰©ä½“åç§°ã€‚

```python
from ultralytics import YOLO
import cv2

def detect():
    model = YOLO("yolo11n.pt")
    results = model(["imgs/20250210101802.png", "imgs/20240731142129234.jpg", "imgs/cat.jpg"])

    for result in results:
        # print(type(result)) # <class 'ultralytics.engine.results.Results'>
        boxes = result.boxes  # Boxes object for bounding box outputs
        masks = result.masks  # Masks object for segmentation masks outputs
        keypoints = result.keypoints  # Keypoints object for pose outputs
        probs = result.probs  # Probs object for classification outputs
        obb = result.obb  # Oriented boxes object for OBB outputs

        result.show()  # display to screen
        # result.save(filename="result.jpg")  # save to disk
```

```bash
results æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œresult ç±»å‹ä¸º <class 'ultralytics.engine.results.Results'>

Attributes:
        orig_img (numpy.ndarray): The original image as a numpy array.
        orig_shape (Tuple[int, int]): Original image shape in (height, width) format.
        boxes (Boxes | None): Detected bounding boxes.
        masks (Masks | None): Segmentation masks.
        probs (Probs | None): Classification probabilities.
        keypoints (Keypoints | None): Detected keypoints.
        obb (OBB | None): Oriented bounding boxes.
        speed (Dict): Dictionary containing inference speed information.
        names (Dict): Dictionary mapping class indices to class names.
        path (str): Path to the input image file.
        save_dir (str | None): Directory to save results.

    Methods:
        update: Updates the Results object with new detection data.
        cpu: Returns a copy of the Results object with all tensors moved to CPU memory.
        numpy: Converts all tensors in the Results object to numpy arrays.
        cuda: Moves all tensors in the Results object to GPU memory.
        to: Moves all tensors to the specified device and dtype.
        new: Creates a new Results object with the same image, path, names, and speed attributes.
        plot: Plots detection results on an input RGB image.
        show: Displays the image with annotated inference results.
        save: Saves annotated inference results image to file.
        verbose: Returns a log string for each task in the results.
        save_txt: Saves detection results to a text file.
        save_crop: Saves cropped detection images to specified directory.
        summary: Converts inference results to a summarized dictionary.
        to_df: Converts detection results to a Pandas Dataframe.
        to_json: Converts detection results to JSON format.
        to_csv: Converts detection results to a CSV format.
        to_xml: Converts detection results to XML format.
        to_html: Converts detection results to HTML format.
        to_sql: Converts detection results to an SQL-compatible format.
```

`show()`æ˜¯æ‰“å¼€å›¾ç‰‡æŸ¥çœ‹å™¨å±•ç¤ºå›¾ç‰‡ã€‚

`plot()`æ˜¯è¿”å›ç»“æœå›¾ç‰‡çš„ `numpy.ndarray`æ•°ç»„ï¼Œè¿™æ ·å°±å¯ä»¥ä½¿ç”¨`cv2`æ¥å¤„ç†å›¾ç‰‡äº†ï¼Œå…¶å·²ç»å®‰è£…äº†`opencv-python`ã€‚å¯¹äºè§†é¢‘æµï¼Œé‚£æœ€å¥½æ˜¯ç”¨`cv2.imshow`ï¼Œä½¿ç”¨åŒä¸€ä¸ªçª—å£åç§°ï¼Œå°±åªæœ‰ä¸€ä¸ªçª—å£ã€‚

```python
def detect():
    model = YOLO("yolo11n.pt")
    results = model(["imgs/20250210101802.png", "imgs/20240731142129234.jpg", "imgs/cat.jpg"])
    for k, result in enumerate(results):
            im = result.plot()  # numpy.ndarray
            cv2.imshow("test"+str(k), im)

    cv2.waitKey(0)
```

è¾“å‡ºä¿¡æ¯

```bash
0: 640x640 1 person, 1 sports ball, 1 tennis racket, 138.6ms
1: 640x640 3 persons, 3 cars, 138.6ms
2: 640x640 1 cat, 138.6ms
Speed: 6.8ms preprocess, 138.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)
```

![image-20250313152319292](D:\dev\php\magook\trunk\server\md\img\image-20250313152319292.png)

![image-20250313161612139](D:\dev\php\magook\trunk\server\md\img\image-20250313161612139.png)

![image-20250313161632257](D:\dev\php\magook\trunk\server\md\img\image-20250313161632257.png)



#### 2ã€Segment

å®ä¾‹åˆ†å‰²æ¯”å¯¹è±¡æ£€æµ‹æ›´è¿›ä¸€æ­¥ï¼Œå®ƒæ¶‰åŠè¯†åˆ«å›¾åƒä¸­çš„å•ä¸ªå¯¹è±¡ï¼Œå¹¶å°†å®ƒä»¬ä»å›¾åƒçš„å…¶ä½™éƒ¨åˆ†ä¸­åˆ†å‰²å‡ºæ¥ã€‚

å®ä¾‹åˆ†å‰²æ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸€ç»„æ©ç æˆ–è½®å»“ï¼Œè¿™äº›æ©ç æˆ–è½®å»“å‹¾å‹’å‡ºå›¾åƒä¸­çš„æ¯ä¸ªå¯¹è±¡ï¼Œå¹¶ä¸”æ¯ä¸ªå¯¹è±¡éƒ½é™„æœ‰ç±»åˆ«æ ‡ç­¾å’Œç½®ä¿¡åº¦åˆ†æ•°ã€‚å½“ä½ ä¸ä»…éœ€è¦çŸ¥é“å›¾åƒä¸­å¯¹è±¡çš„ä½ç½®ï¼Œè¿˜éœ€è¦äº†è§£å®ƒä»¬çš„ç¡®åˆ‡å½¢çŠ¶æ—¶ï¼Œå®ä¾‹åˆ†å‰²å°±éå¸¸æœ‰ç”¨ã€‚

![image-20250313152852101](D:\dev\php\magook\trunk\server\md\img\image-20250313152852101.png)

```python
def segment():
    model = YOLO("yolo11n-seg.pt")
    results = model(["imgs/20250210101802.png"])

    for k, result in enumerate(results):
        filename = util.generate_random_string(15)
        result.save(filename="imgs_result/"+filename+".jpg")
```

![image-20250313165311348](D:\dev\php\magook\trunk\server\md\img\image-20250313165311348.png)



#### 3ã€Pose

å§¿æ€ä¼°è®¡æ˜¯ä¸€é¡¹æ¶‰åŠè¯†åˆ«å›¾åƒä¸­ç‰¹å®šç‚¹çš„ä½ç½®çš„ä»»åŠ¡ï¼Œè¿™äº›ç‚¹é€šå¸¸è¢«ç§°ä¸ºå…³é”®ç‚¹ã€‚å…³é”®ç‚¹å¯ä»¥ä»£è¡¨å¯¹è±¡çš„å„ç§éƒ¨åˆ†ï¼Œå¦‚å…³èŠ‚ã€æ ‡å¿—ç‚¹æˆ–å…¶ä»–æ˜¾è‘—ç‰¹å¾ã€‚å…³é”®ç‚¹çš„ä½ç½®é€šå¸¸ä»¥ä¸€ç»„2D [x, y]æˆ–3D [x, y, å¯è§æ€§]åæ ‡è¡¨ç¤ºã€‚

å§¿æ€ä¼°è®¡æ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸€ç»„ä»£è¡¨å›¾åƒä¸­å¯¹è±¡ä¸Šçš„å…³é”®ç‚¹çš„ç‚¹ï¼Œé€šå¸¸è¿˜é™„æœ‰æ¯ä¸ªç‚¹çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚å½“ä½ éœ€è¦è¯†åˆ«åœºæ™¯ä¸­å¯¹è±¡çš„å…·ä½“éƒ¨åˆ†åŠå…¶ç›¸äº’ä¹‹é—´çš„ä½ç½®å…³ç³»æ—¶ï¼Œå§¿æ€ä¼°è®¡æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ã€‚

ä½¿ç”¨çš„æ˜¯ `coco-pose`æ•°æ®é›†ã€‚

äººçš„å§¿æ€è¢«å®šä¹‰ä¸º17ä¸ªç‚¹ï¼Œå¹¶æ ‡è®°æ¯ä¸ªç‚¹åœ¨å›¾åƒä¸­çš„åæ ‡

```bash
Nose
Left Eye
Right Eye
Left Ear
Right Ear
Left Shoulder
Right Shoulder
Left Elbow
Right Elbow
Left Wrist
Right Wrist
Left Hip
Right Hip
Left Knee
Right Knee
Left Ankle
Right Ankle
```



```python
def pose():
    model = YOLO("yolo11n-pose.pt")  # load an official model
    results = model("imgs/20250210101802.png")

    for result in results:
        print(result.keypoints)
        result.show()
```

![image-20250313180124063](D:\dev\php\magook\trunk\server\md\img\image-20250313180124063.png)

```bash
ultralytics.engine.results.Keypoints object with attributes:

conf: tensor([[0.9966, 0.9942, 0.9561, 0.9619, 0.3857, 0.9993, 0.9988, 0.9974, 0.9947, 0.9763, 0.9706, 0.9999, 0.9998, 0.9985, 0.9982, 0.9850, 0.9847]])
data: tensor([[[2.1565e+02, 3.4999e+01, 9.9656e-01],
         [2.1984e+02, 2.7018e+01, 9.9415e-01],
         [2.0907e+02, 3.1001e+01, 9.5614e-01],
         [2.3481e+02, 2.5937e+01, 9.6186e-01],
         [0.0000e+00, 0.0000e+00, 3.8572e-01],
         [2.5573e+02, 4.5721e+01, 9.9928e-01],
         [2.0819e+02, 6.0532e+01, 9.9878e-01],
         [2.8809e+02, 6.5891e+01, 9.9740e-01],
         [1.5987e+02, 8.1759e+01, 9.9467e-01],
         [3.2300e+02, 1.0970e+02, 9.7626e-01],
         [1.1831e+02, 8.0122e+01, 9.7056e-01],
         [2.5918e+02, 1.3346e+02, 9.9990e-01],
         [2.0929e+02, 1.4076e+02, 9.9985e-01],
         [3.3731e+02, 1.8365e+02, 9.9854e-01],
         [1.6218e+02, 1.9817e+02, 9.9822e-01],
         [3.9673e+02, 2.3521e+02, 9.8505e-01],
         [9.3972e+01, 2.5031e+02, 9.8471e-01]]])
has_visible: True
orig_shape: (299, 478)
shape: torch.Size([1, 17, 3])
xy: tensor([[[215.6517,  34.9987],
         [219.8361,  27.0179],
         [209.0718,  31.0013],
         [234.8076,  25.9374],
         [  0.0000,   0.0000],
         [255.7305,  45.7213],
         [208.1883,  60.5316],
         [288.0875,  65.8907],
         [159.8745,  81.7594],
         [323.0020, 109.6960],
         [118.3133,  80.1224],
         [259.1849, 133.4618],
         [209.2867, 140.7613],
         [337.3135, 183.6483],
         [162.1798, 198.1695],
         [396.7317, 235.2071],
         [ 93.9718, 250.3072]]])
xyn: tensor([[[0.4512, 0.1171],
         [0.4599, 0.0904],
         [0.4374, 0.1037],
         [0.4912, 0.0867],
         [0.0000, 0.0000],
         [0.5350, 0.1529],
         [0.4355, 0.2024],
         [0.6027, 0.2204],
         [0.3345, 0.2734],
         [0.6757, 0.3669],
         [0.2475, 0.2680],
         [0.5422, 0.4464],
         [0.4378, 0.4708],
         [0.7057, 0.6142],
         [0.3393, 0.6628],
         [0.8300, 0.7866],
         [0.1966, 0.8371]]])
```

`conf`ï¼šæ¯ä¸ªç‚¹çš„ç½®ä¿¡åº¦

`xy`ï¼šæ¯ä¸€ä¸ªç‚¹çš„x,yåæ ‡

`xyn`ï¼šåæ ‡æ ‡å‡†åŒ–

`data`ï¼šx, y, visibility



#### 4ã€Classify

å›¾åƒåˆ†ç±»æ˜¯è¿™ä¸‰ä¸ªä»»åŠ¡ä¸­æœ€ç®€å•çš„ï¼Œå®ƒæ¶‰åŠå°†æ•´å¼ å›¾åƒå½’ç±»åˆ°ä¸€ç»„é¢„å®šä¹‰çš„ç±»åˆ«ä¸­çš„ä¸€ç§ã€‚

å›¾åƒåˆ†ç±»å™¨çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå•ä¸€çš„ç±»åˆ«æ ‡ç­¾å’Œä¸€ä¸ªç½®ä¿¡åº¦åˆ†æ•°ã€‚å½“ä½ åªéœ€è¦çŸ¥é“å›¾åƒå±äºå“ªä¸ªç±»åˆ«ï¼Œè€Œä¸éœ€è¦çŸ¥é“è¯¥ç±»åˆ«çš„å¯¹è±¡åœ¨å›¾åƒä¸­çš„å…·ä½“ä½ç½®æˆ–å®ƒä»¬çš„ç¡®åˆ‡å½¢çŠ¶æ—¶ï¼Œå›¾åƒåˆ†ç±»å°±éå¸¸æœ‰ç”¨ã€‚

ä½¿ç”¨çš„æ˜¯`imageNet`æ•°æ®é›†ï¼Œé‡Œé¢æœ‰1000ä¸ªç±»åˆ«ã€‚

```python
def classify():
    model = YOLO("yolo11m-cls.pt")
    results = model(["imgs/20250210101802.png"])

    for k, result in enumerate(results):
        print(result.probs)
        result.show()
```

`imgs/20250210101802.png`æ˜¯ä¸Šé¢çš„æ‰“ç¾½æ¯›çƒçš„å›¾ç‰‡ã€‚

è¾“å‡ºç»“æœ

```bash
......
orig_shape: None
shape: torch.Size([1000])
top1: 752
top1conf: tensor(0.9599)
top5: [752, 852, 890, 722, 422]
top5conf: tensor([0.9599, 0.0154, 0.0079, 0.0037, 0.0026])
```

`top1: 752`ä»£è¡¨åˆ†ç±»IDï¼Œæ‰“å¼€`ultralytics\cfg\datasets\ImageNet.yaml`æ–‡ä»¶ï¼Œæœç´¢åˆ°`752: racket`ï¼Œå°±æ˜¯çƒæ‹çš„æ„æ€ã€‚

`top1conf: tensor(0.9599)`ä»£è¡¨ top1 çš„å¾—åˆ†ã€‚

`top5`å’Œ`top5conf`ä»£è¡¨ top5 çš„åˆ†ç±»ã€‚

ä»å¾—åˆ†æ¥çœ‹ï¼Œtop1 è¿œè¿œè¶…è¿‡äº†å…¶ä»–å››ä¸ªã€‚

![image-20250313181129539](D:\dev\php\magook\trunk\server\md\img\image-20250313181129539.png)



#### 5ã€Track

https://docs.ultralytics.com/modes/track/

![image-20250314141356363](D:\dev\php\magook\trunk\server\md\img\image-20250314141356363.png)

åœ¨è§†é¢‘åˆ†æé¢†åŸŸä¸­ï¼Œå¯¹è±¡è·Ÿè¸ªæ˜¯ä¸€é¡¹è‡³å…³é‡è¦çš„ä»»åŠ¡ï¼Œå®ƒä¸ä»…èƒ½å¤Ÿè¯†åˆ«å¸§å†…å¯¹è±¡çš„ä½ç½®å’Œç±»åˆ«ï¼Œè€Œä¸”è¿˜èƒ½åœ¨è§†é¢‘è¿›è¡Œè¿‡ç¨‹ä¸­ä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„å¯¹è±¡ç»´æŒä¸€ä¸ªå”¯ä¸€çš„IDã€‚è¯¥æŠ€æœ¯çš„åº”ç”¨èŒƒå›´éå¸¸å¹¿æ³›ï¼Œä» surveillanceï¼ˆç›‘æ§ï¼‰å’Œå®‰å…¨åˆ°å®æ—¶ä½“è‚²åˆ†æç­‰é¢†åŸŸéƒ½æœ‰æ¶‰åŠã€‚

æ¥è‡ªUltralyticsè·Ÿè¸ªå™¨çš„è¾“å‡ºä¸æ ‡å‡†å¯¹è±¡æ£€æµ‹ä¸€è‡´ï¼Œä½†å¢åŠ äº†å¯¹è±¡IDçš„ä»·å€¼ã€‚è¿™ä½¿å¾—åœ¨è§†é¢‘æµä¸­è·Ÿè¸ªå¯¹è±¡å¹¶æ‰§è¡Œåç»­åˆ†æå˜å¾—å®¹æ˜“ã€‚

Ultralytics YOLO æä¾›äº†ä¸¤ä¸ªè·Ÿè¸ªç®—æ³•ï¼Œä½ éœ€è¦åœ¨ YAML é…ç½®æ–‡ä»¶ä¸­è®¾ç½®`tracker=tracker_type.yaml`ï¼Œå¯é€‰çš„å€¼ä¸º`botsort.yaml å’Œ bytetrack.yaml`ï¼Œé»˜è®¤å€¼æ˜¯`botsort`ã€‚

ä½ å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„`Detect / Segment / Pose`æ¨¡å‹ï¼Œåœ¨è§†é¢‘æµä¸Šè¿è¡Œè¿½è¸ªå™¨ï¼Œæ¯”å¦‚`YOLO11n, YOLO11n-seg, YOLO11n-pose`ã€‚

```python
def track():
    model = YOLO("yolo11n.pt")
	
    # Tracking with default tracker
    results = model.track("https://youtu.be/LNwODJXcvt4", show=True)  
    
    # with ByteTrack
    # results = model.track("https://youtu.be/LNwODJXcvt4", show=True, tracker="bytetrack.yaml")  
    
    for result in results:
        print(result.boxes.id)  # print track IDs
        result.show()
        
def track2():
    model = YOLO("yolo11n.pt")
    video_path = "path/to/video.mp4"
    cap = cv2.VideoCapture(video_path)

    while cap.isOpened():
        success, frame = cap.read()

        if success:
            # Run YOLO11 tracking on the frame, persisting tracks between frames
            results = model.track(frame, persist=True)

            annotated_frame = results[0].plot()

            cv2.imshow("YOLO11 Tracking", annotated_frame)

            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
        else:
            break

    cap.release()
    cv2.destroyAllWindows()
    
    
def track3():
    model = YOLO("yolo11n.pt")
    video_path = "path/to/video.mp4"
    cap = cv2.VideoCapture(video_path)

    # Store the track history
    track_history = defaultdict(lambda: [])

    # Loop through the video frames
    while cap.isOpened():
        # Read a frame from the video
        success, frame = cap.read()

        if success:
            # Run YOLO11 tracking on the frame, persisting tracks between frames
            results = model.track(frame, persist=True)

            # Get the boxes and track IDs
            boxes = results[0].boxes.xywh.cpu()
            track_ids = results[0].boxes.id.int().cpu().tolist()

            # Visualize the results on the frame
            annotated_frame = results[0].plot()

            # Plot the tracks
            for box, track_id in zip(boxes, track_ids):
                x, y, w, h = box
                track = track_history[track_id]
                track.append((float(x), float(y)))  # x, y center point
                if len(track) > 30:  # retain 90 tracks for 90 frames
                    track.pop(0)

                # Draw the tracking lines
                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))
                cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)

            # Display the annotated frame
            cv2.imshow("YOLO11 Tracking", annotated_frame)

            # Break the loop if 'q' is pressed
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
        else:
            # Break the loop if the end of the video is reached
            break

    # Release the video capture object and close the display window
    cap.release()
    cv2.destroyAllWindows()

    
def track4():
    # Define model names and video sources
    MODEL_NAMES = ["yolo11n.pt", "yolo11n-seg.pt"]
    SOURCES = ["path/to/video.mp4", "0"]  # local video, 0 for webcam


    def run_tracker_in_thread(model_name, filename):
        """
        Run YOLO tracker in its own thread for concurrent processing.

        Args:
            model_name (str): The YOLO11 model object.
            filename (str): The path to the video file or the identifier for the webcam/external camera source.
        """
        model = YOLO(model_name)
        results = model.track(filename, save=True, stream=True)
        for r in results:
            pass

    # Create and start tracker threads using a for loop
    tracker_threads = []
    for video_file, model_name in zip(SOURCES, MODEL_NAMES):
        thread = threading.Thread(target=run_tracker_in_thread, args=(model_name, video_file), daemon=True)
        tracker_threads.append(thread)
        thread.start()

    # Wait for all tracker threads to finish
    for thread in tracker_threads:
        thread.join()

    # Clean up and close windows
    cv2.destroyAllWindows()

```



#### 6ã€OBB

Oriented Bounding Boxes Object Detectionï¼Œå®šå‘ç‰©ä½“æ£€æµ‹ï¼Œç”»å‡ºæ¥çš„è¾¹ç•Œæ¡†å¸¦æœ‰ä¸€ä¸ªå€¾æ–œè§’åº¦ã€‚

å®šå‘å¯¹è±¡æ£€æµ‹æ¯”ä¼ ç»Ÿå¯¹è±¡æ£€æµ‹æ›´è¿›ä¸€æ­¥ï¼Œå®ƒå¼•å…¥äº†ä¸€ä¸ªé¢å¤–çš„è§’åº¦æ¥æ›´ç²¾ç¡®åœ°å®šä½å›¾åƒä¸­çš„å¯¹è±¡ã€‚

å®šå‘å¯¹è±¡æ£€æµ‹å™¨çš„è¾“å‡ºæ˜¯ä¸€ç»„æ—‹è½¬çš„è¾¹ç•Œæ¡†ï¼Œè¿™äº›æ¡†ç²¾ç¡®åœ°åŒ…å›´äº†å›¾åƒä¸­çš„å¯¹è±¡ï¼Œå¹¶ä¸”æ¯ä¸ªæ¡†éƒ½é™„æœ‰ç±»åˆ«æ ‡ç­¾å’Œç½®ä¿¡åº¦åˆ†æ•°ã€‚å½“ä½ éœ€è¦è¯†åˆ«åœºæ™¯ä¸­çš„æ„Ÿå…´è¶£å¯¹è±¡ï¼Œä½†ä¸éœ€è¦çŸ¥é“å¯¹è±¡çš„ç¡®åˆ‡ä½ç½®æˆ–å…¶ç¡®åˆ‡å½¢çŠ¶æ—¶ï¼Œå¯¹è±¡æ£€æµ‹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ã€‚

ä½¿ç”¨çš„æ•°æ®é›†æ˜¯ `DOTAv1`

```python
def obb():
    model = YOLO("yolo11n-obb.pt")
    results = model(["imgs/boats.jpg"])

    for result in results:
        # print(result.obb)

        # xywhr = result.obb.xywhr  # center-x, center-y, width, height, angle (radians)
        # xyxyxyxy = result.obb.xyxyxyxy  # polygon format with 4-points
        # names = [result.names[cls.item()] for cls in result.obb.cls.int()]  # class name of each box
        # confs = result.obb.conf  # confidence score of each box

        filename = util.generate_random_string(15)
        result.save(filename="imgs_result/"+filename+".jpg")
```

![image-20250314171720310](D:\dev\php\magook\trunk\server\md\img\image-20250314171720310.png)

![image-20250314172505181](D:\dev\php\magook\trunk\server\md\img\image-20250314172505181.png)



### ä¸‰ã€è®­ç»ƒYOLO11æ¨¡å‹çš„ Detection Task

å¦‚æœä½ è¦æ£€æµ‹çš„å¯¹è±¡åœ¨YOLO11çš„è®­ç»ƒé›†ä¸Šæ²¡æœ‰ï¼Œæˆ–è€…ä½ çš„ä½¿ç”¨åœºæ™¯ä¸åŒå¯¼è‡´é¢„è®­ç»ƒæ¨¡å‹çš„æ•ˆæœä¸ä½³ï¼Œé‚£å°±éœ€è¦è‡ªå·±æ¥å‡†å¤‡æ•°æ®é›†å’Œè®­ç»ƒäº†ã€‚

ä»¥ Detection Task ä¸ºä¾‹ï¼šhttps://docs.ultralytics.com/tasks/detect/#train

Train YOLO11n on the COCO8 dataset for 100 [epochs](https://www.ultralytics.com/glossary/epoch) at image size 640. For a full list of available arguments see the [Configuration](https://docs.ultralytics.com/usage/cfg/) page.

ä»ä¸Šé¢æˆ‘ä»¬çŸ¥é“ï¼ŒDetect æ˜¯åœ¨ COCO æ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œé‚£æ­¤å¤„ä¸ºä»€ä¹ˆåˆè¯´ COCO8ï¼Œè¿™ä¸¤è€…æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**COCO æ•°æ®é›†**

COCOè¯´æ˜ï¼šhttps://docs.ultralytics.com/datasets/detect/coco/

> **COCOï¼ˆCommon Objects in Contextï¼Œå¸¸è§ç‰©ä½“ä¸Šä¸‹æ–‡ï¼‰æ•°æ®é›†** æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²å’Œå­—å¹•ç”Ÿæˆæ•°æ®é›†ã€‚å®ƒæ—¨åœ¨é¼“åŠ±å¯¹å¹¿æ³›ç‰©ä½“ç±»åˆ«è¿›è¡Œç ”ç©¶ï¼Œå¹¶å¸¸ç”¨äºè®¡ç®—æœºè§†è§‰æ¨¡å‹çš„æ€§èƒ½åŸºå‡†æµ‹è¯•ã€‚å¯¹äºä»äº‹ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ä»»åŠ¡çš„ç ”ç©¶äººå‘˜åŠå¼€å‘è€…è€Œè¨€ï¼ŒCOCOæ•°æ®é›†æ˜¯ä¸å¯æˆ–ç¼ºçš„æ ¸å¿ƒèµ„æºã€‚

COCO è®­ç»ƒäº† `YOLO11n ~ YOLO11x`æ¨¡å‹

COCO å®˜ç½‘ï¼šhttps://cocodataset.org/#home

ä¸»è¦ç‰¹ç‚¹

- COCOæ•°æ®é›†åŒ…å«äº†33ä¸‡å¼ å›¾åƒï¼Œå…¶ä¸­20ä¸‡å¼ å›¾åƒå…·æœ‰é’ˆå¯¹ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²å’Œå­—å¹•ç”Ÿæˆä»»åŠ¡çš„æ ‡æ³¨ã€‚
- è¯¥æ•°æ®é›†åŒ…å«äº†80ä¸ªç‰©ä½“ç±»åˆ«ï¼ŒåŒ…æ‹¬åƒæ±½è½¦ã€è‡ªè¡Œè½¦å’ŒåŠ¨ç‰©è¿™æ ·çš„å¸¸è§ç‰©ä½“ï¼Œä»¥åŠæ›´å…·ä½“çš„ç±»åˆ«ï¼Œå¦‚é›¨ä¼ã€æ‰‹æåŒ…å’Œè¿åŠ¨å™¨æã€‚
- æ ‡æ³¨ä¿¡æ¯åŒ…æ‹¬æ¯ä¸ªå›¾åƒçš„å¯¹è±¡è¾¹ç•Œæ¡†ã€åˆ†å‰²æ©è†œå’Œå­—å¹•ã€‚
- COCOæä¾›äº†æ ‡å‡†åŒ–çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ç”¨äºç›®æ ‡æ£€æµ‹çš„å¹³å‡ç²¾åº¦å‡å€¼ï¼ˆmAPï¼‰å’Œç”¨äºåˆ†å‰²ä»»åŠ¡çš„å¹³å‡å¬å›ç‡å‡å€¼ï¼ˆmARï¼‰ï¼Œä½¿å…¶é€‚åˆäºæ¯”è¾ƒæ¨¡å‹æ€§èƒ½ã€‚

æ‰“å¼€`ultralytics\cfg\datasets\coco.yaml`æ–‡ä»¶

```bash
urls = [
	"http://images.cocodataset.org/zips/train2017.zip",  # 19G, 118k images
	"http://images.cocodataset.org/zips/val2017.zip",  # 1G, 5k images
	"http://images.cocodataset.org/zips/test2017.zip",  # 7G, 41k images (optional)
]
```



**COCO8 æ•°æ®é›†**

è¿™æ˜¯ä¸€ä¸ªå°æ•°æ®é›†ï¼Œç”¨äºå¯¹è±¡æ£€æµ‹ï¼Œå®ƒåŒ…å« COCO train2017 ä¸­çš„å‰8å¼ å›¾ç‰‡ï¼Œ4ä¸ªæ˜¯ç”¨æ¥è®­ç»ƒï¼Œ4ä¸ªç”¨æ¥éªŒè¯ã€‚COCO8 æ˜¯tesing å’Œ debugging å¯¹è±¡æ£€æµ‹æ¨¡å‹çš„ç†æƒ³æ•°æ®é›†ï¼Œæˆ–è€…å®éªŒæ–°çš„æ£€æµ‹æ–¹æ³•ã€‚å…¶zipå¤§å°åªæœ‰1Mã€‚

coco8çš„yamlå®šä¹‰è·Ÿcocoå‡ ä¹ä¸€æ ·ã€‚è™½ç„¶å®ƒåªæœ‰8å¼ å›¾ç‰‡ï¼Œä½†æ˜¯æ¯å¼ å›¾ç‰‡ä¸Šå¯ä»¥æœ‰å¤šä¸ªå¯¹è±¡ï¼Œå› æ­¤ï¼Œå®ƒä¾ç„¶æœ‰80ä¸ªåˆ†ç±»ã€‚

![image-20250318155438995](D:\dev\php\magook\trunk\server\md\img\image-20250318155438995.png)



**imageNet æ•°æ®é›†**

åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸè¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰åçš„æ•°æ®é›†ï¼Œå®ƒçš„ç‰¹ç‚¹æ˜¯ä¸€å¼ å›¾ç‰‡ä¸Šåªèšç„¦ä¸€ä¸ªå¯¹è±¡ï¼Œä¹Ÿå°±è¯´ä¸€ä¸ªå›¾ç‰‡åªä¼šè¢«è¯†åˆ«æˆä¸€ä¸ªå¯¹è±¡ï¼Œæ‰€ä»¥è¢«ç”¨æ¥åšclassificationã€‚

![image-20250318160322904](D:\dev\php\magook\trunk\server\md\img\image-20250318160322904.png)

å®˜ç½‘ https://www.image-net.org/



**å‡†å¤‡æ•°æ®é›†**

æˆ‘ä»¬å…ˆæ¥å‚è€ƒä¸€ä¸‹ [coco8](https://github.com/ultralytics/assets/releases/download/v0.0.0/coco8.zip) ï¼Œä¸‹è½½è§£å‹å

```bash
tree coco8

coco8
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ images
â”‚Â Â  â”œâ”€â”€ train
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 000000000009.jpg
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 000000000025.jpg
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 000000000030.jpg
â”‚Â Â  â”‚Â Â  â””â”€â”€ 000000000034.jpg
â”‚Â Â  â””â”€â”€ val
â”‚Â Â      â”œâ”€â”€ 000000000036.jpg
â”‚Â Â      â”œâ”€â”€ 000000000042.jpg
â”‚Â Â      â”œâ”€â”€ 000000000049.jpg
â”‚Â Â      â””â”€â”€ 000000000061.jpg
â””â”€â”€ labels
    â”œâ”€â”€ train
    â”‚Â Â  â”œâ”€â”€ 000000000009.txt
    â”‚Â Â  â”œâ”€â”€ 000000000025.txt
    â”‚Â Â  â”œâ”€â”€ 000000000030.txt
    â”‚Â Â  â””â”€â”€ 000000000034.txt
    â””â”€â”€ val
        â”œâ”€â”€ 000000000036.txt
        â”œâ”€â”€ 000000000042.txt
        â”œâ”€â”€ 000000000049.txt
        â””â”€â”€ 000000000061.txt
```

`images`é‡Œé¢æ”¾çš„æ˜¯åŸå§‹å›¾ç‰‡ï¼Œ`labels`æ”¾çš„æ˜¯æ ‡ç­¾ä¿¡æ¯ã€‚

`000000000009.jpg`

![image-20250318172611750](D:\dev\php\magook\trunk\server\md\img\image-20250318172611750.png)

`000000000009.txt`

```txt
45 0.479492 0.688771 0.955609 0.5955
45 0.736516 0.247188 0.498875 0.476417
50 0.637063 0.732938 0.494125 0.510583
45 0.339438 0.418896 0.678875 0.7815
49 0.646836 0.132552 0.118047 0.0969375
49 0.773148 0.129802 0.0907344 0.0972292
49 0.668297 0.226906 0.131281 0.146896
49 0.642859 0.0792187 0.148063 0.148062
```

åˆ†åˆ«ä¸ºï¼šå¯¹è±¡IDï¼Œæ ‡æ³¨æ¡†ä¸­å¿ƒç‚¹Xåæ ‡ï¼ˆå½’ä¸€åŒ–å€¼ï¼‰ï¼Œæ ‡æ³¨æ¡†ä¸­å¿ƒç‚¹Yåæ ‡ï¼Œæ ‡æ³¨æ¡†å®½ï¼Œæ ‡æ³¨æ¡†é«˜



**è‡ªå·±æ ‡æ³¨**

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `labelimg`å·¥å…·æ¥è‡ªå·±æ ‡æ³¨ã€‚

å‚è€ƒï¼š[æ·±åº¦å­¦ä¹ å·¥å…·|LabelImgï¼ˆæ ‡æ³¨å·¥å…·ï¼‰çš„å®‰è£…ä¸ä½¿ç”¨æ•™ç¨‹](https://blog.csdn.net/StopAndGoyyy/article/details/139906637)

![image-20250318173355028](D:\dev\php\magook\trunk\server\md\img\image-20250318173355028.png)

```bash
â”œâ”€â”€ classes.txt
â”œâ”€â”€ å¾®ä¿¡æˆªå›¾_20250210101900.txt
â””â”€â”€ å¾®ä¿¡æˆªå›¾_20250210101922.txt
```

`å¾®ä¿¡æˆªå›¾_20250210101922.txt`

```txt
0 0.574367 0.505495 0.541139 0.824176
1 0.313291 0.195055 0.234177 0.351648
```

è¿™é‡Œçš„0, 1æ˜¯åºå·è€Œä¸æ˜¯å¯¹è±¡ID

`classes.txt`

```txt
0
38
```

è¿™æ‰æ˜¯å¯¹è±¡ID

å¾—åˆ°çš„ç»“æ„ä¸ coco8 è¿˜ä¸ä¸€æ ·ï¼Œè¿˜éœ€è¦å°†å¯¹è±¡IDå¡«å……è¿›å»ã€‚



å¦‚æœæ²¡æœ‰è‡ªå·±çš„æ•°æ®é›†ï¼Œæœ¬æ–‡æä¾›ä¸€ä¸ªå°å‹æ•°æ®é›†ï¼ˆæ‘˜è‡ªSIMDå…¬å…±æ•°æ®é›†ï¼‰ä»¥ä¾›æµ‹è¯•ä»£ç ï¼ŒåŒ…å«24å¼ è®­ç»ƒé›†ä»¥åŠ20å¼ æµ‹è¯•é›†ï¼Œçº¦17.7MBï¼Œç™¾åº¦äº‘é“¾æ¥ï¼šhttps://pan.baidu.com/s/1sCivMDjfAmUZK1J2P2_Dtg?pwd=1234

æˆ‘ä»¬ä½¿ç”¨è‡ªæœ‰æ•°æ®é›†æ¥è®­ç»ƒæ¨¡å‹ï¼Œä¹Ÿéœ€è¦æŒ‰ç…§ `coco.yaml`çš„æ ¼å¼æ¥å®šä¹‰é…ç½®

`train` è®­ç»ƒé›†ï¼Œ`val`éªŒè¯é›†ï¼Œ`test`æµ‹è¯•é›†

åœ¨å®šä¹‰`train/val/test`çš„æ—¶å€™ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶å¤¹ï¼ˆæ¯”å¦‚ coco8.yamlï¼‰ï¼Œè¡¨ç¤ºè¿™ä¸ªç›®å½•ä¸‹çš„å›¾ç‰‡æ˜¯åšè¿™ä¸ªäº‹çš„ï¼Œå½“ç„¶ä½ è¦å°†å›¾ç‰‡å¤åˆ¶è¿›å»ã€‚ä¹Ÿå¯ä»¥æ˜¯`xxx.txt`æ–‡ä»¶ï¼ˆæ¯”å¦‚ coco.yamlï¼‰ï¼ŒæŠŠå›¾ç‰‡æ–‡ä»¶ååˆ—è¿›å»ã€‚

```bash
path: ../datasets/coco # dataset root dir
train: train2017.txt # train images (relative to 'path') 118287 images
val: val2017.txt # val images (relative to 'path') 5000 images
test: test-dev2017.txt
```

```bash
path: ../datasets/coco8 # dataset root dir
train: images/train # train images (relative to 'path') 4 images
val: images/val # val images (relative to 'path') 4 images
test: # test images (optional)
```



å°†SIMDå…¬å…±æ•°æ®é›†è§£å‹åˆ° `datasets/simd` ç›®å½•ä¸‹

`simd.yaml`

```yaml
# dataset path
path: D:\dev\php\magook\trunk\server\learn-yolo\datasets\simd
train: images/train
val: images/test
test: images/test

# Classes
names:
  0: "car"
  1: "Truck"
  2: "Van"
  3: "Long Vehicle"
  4: "Bus"
  5: "Airliner"
  6: "Propeller Aircraft"
  7: "Trainer Aircraft"
  8: "Chartered Aircraft"
  9: "Fighter Aircraft"
  10: "Others"
  11: "Stair Truck"
  12: "Pushback Truck"
  13: "Helicopter"
  14: "Boat"
```

path æœ€å¥½å¡«ç»å¯¹è·¯å¾„ï¼Œå¦åˆ™å®ƒä¼šä½¿ç”¨`DATASETS_DIR + path`ï¼Œè€Œ`DATASETS_DIR`çš„å€¼åœ¨`C:\Users\Administrator.DESKTOP-TPJL4TC\AppData\Roaming\Ultralytics\settings.json`ä¸­ã€‚

![image-20250319101538278](D:\dev\php\magook\trunk\server\md\img\image-20250319101538278.png)

**è®­ç»ƒæ¨¡å‹**

```python
def train():
   os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
   model = YOLO('yolo11n.pt')

   results = model.train(data='./simd.yaml', epochs=10, batch=1, imgsz=640, cache=False,
                          amp=True, mosaic=False, project='runs/train', name='exp')
```

- epochs è®­ç»ƒå¤šå°‘è½®ï¼Œé€šå¸¸è¦å¤§äº100
- cache æ˜¯å¦ç¼“å­˜æ•°æ®é›†ä»¥åŠ å¿«åç»­è®­ç»ƒé€Ÿåº¦
- batch è¾“å…¥ç«¯æ¯æ¬¡è¾“å…¥å‡ å¼ å›¾ç‰‡ï¼Œè¿™ä¸ªå—é™äºå†…å­˜å¤§å°
- workers è®¾ç½®ç”¨äºæ•°æ®åŠ è½½çš„çº¿ç¨‹æ•°ï¼Œæ›´å¤šçº¿ç¨‹å¯ä»¥åŠ å¿«æ•°æ®åŠ è½½é€Ÿåº¦







Train Settingsï¼šhttps://docs.ultralytics.com/usage/cfg/#train-settings

```bash
Ultralytics 8.3.89 ğŸš€ Python-3.11.4 torch-2.6.0+cpu CPU (Intel Core(TM) i7-4790 3.60GHz)
engine\trainer: task=detect, mode=train, model=yolo11n.pt, data=./simd.yaml, epochs=10, time=None, patience=100, batch=1, imgsz=640, save=True, save_period=-1, cache=False,
 device=None, workers=8, project=runs/train, name=exp4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=Fa
lse, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=T
rue, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visu
alize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=Fals
e, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None
, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5,
 pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=
False, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\train\exp4
Overriding model.yaml nc=80 with nc=15

                   from  n    params  module                                       arguments
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]
  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]
  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]
  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]
  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]
  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]
  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]
 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]
 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']
 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]
 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]
 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']
 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]
 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]
 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]
 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]
 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]
 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]
 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]
 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]
 23        [16, 19, 22]  1    433597  ultralytics.nn.modules.head.Detect           [15, [64, 128, 256]]
YOLO11n summary: 181 layers, 2,592,765 parameters, 2,592,749 gradients, 6.5 GFLOPs

Transferred 448/499 items from pretrained weights
Freezing layer 'model.23.dfl.conv.weight'
train: Scanning D:\dev\php\magook\trunk\server\learn-yolo\datasets\simd\labels\train... 24 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 88.58it/ss
train: New cache created: D:\dev\php\magook\trunk\server\learn-yolo\datasets\simd\labels\train.cache
val: Scanning D:\dev\php\magook\trunk\server\learn-yolo\datasets\simd\labels\test... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 276.82it/s]
val: New cache created: D:\dev\php\magook\trunk\server\learn-yolo\datasets\simd\labels\test.cache
Plotting labels to runs\train\exp4\labels.jpg...
optimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically...
optimizer: AdamW(lr=0.000526, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)
Image sizes 640 train, 640 val
Using 0 dataloader workers
Logging results to runs\train\exp4
Starting training for 10 epochs...
Closing dataloader mosaic

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       1/10         0G      2.332      5.702       1.51          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:20<00:00,  1.20it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.58it/s]
                   all         20        146          0          0          0          0

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       2/10         0G      2.327      6.118      1.462          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:15<00:00,  1.58it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.16it/s]
                   all         20        146          0          0          0          0

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       3/10         0G      2.239      5.617      1.536          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:14<00:00,  1.69it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.06it/s]
                   all         20        146     0.0224      0.102     0.0308     0.0152

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       4/10         0G      2.199      5.524      1.471          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:13<00:00,  1.78it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.84it/s]
                   all         20        146     0.0224      0.102     0.0308     0.0152

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       5/10         0G       2.15      5.443      1.409          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:13<00:00,  1.79it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.24it/s]
                   all         20        146     0.0224      0.102     0.0308     0.0152

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       6/10         0G      1.882      5.329      1.337          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:13<00:00,  1.72it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.07it/s]
                   all         20        146    0.00469      0.184     0.0375     0.0216

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       7/10         0G      2.071       5.78      1.363         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:13<00:00,  1.77it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.99it/s]
                   all         20        146    0.00469      0.184     0.0375     0.0216

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       8/10         0G      1.929      5.379      1.376          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:13<00:00,  1.76it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.97it/s]
                   all         20        146      0.823    0.00714     0.0493     0.0291

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       9/10         0G      1.745      5.327      1.143          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:13<00:00,  1.79it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.05it/s]
                   all         20        146      0.823    0.00714     0.0493     0.0291

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      10/10         0G      1.818      5.315      1.221          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:13<00:00,  1.78it/s]]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.90it/s]
                   all         20        146      0.823    0.00714     0.0493     0.0291

10 epochs completed in 0.052 hours.
Optimizer stripped from runs\train\exp4\weights\last.pt, 5.5MB
Optimizer stripped from runs\train\exp4\weights\best.pt, 5.5MB

Validating runs\train\exp4\weights\best.pt...
Ultralytics 8.3.89 ğŸš€ Python-3.11.4 torch-2.6.0+cpu CPU (Intel Core(TM) i7-4790 3.60GHz)
YOLO11n summary (fused): 100 layers, 2,585,077 parameters, 0 gradients, 6.3 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.25it/s]
                   all         20        146      0.823    0.00714     0.0486     0.0289
                   car          7         50          1          0          0          0
                 Truck          5         16          1          0          0          0
                   Van          9         23          1          0          0          0
          Long Vehicle          1          7          1          0    0.00252   0.000757
                   Bus          3          5          1          0    0.00539   0.000539
              Airliner         14         14      0.231     0.0714      0.392      0.243
      Trainer Aircraft          2         11          1          0     0.0862     0.0452
                Others          5         10          1          0          0          0
           Stair Truck          5          6          0          0          0          0
        Pushback Truck          3          4          1          0          0          0
Speed: 3.8ms preprocess, 120.5ms inference, 0.0ms loss, 5.8ms postprocess per image
Results saved to runs\train\exp4
...
...
```

ä»è¾“å‡ºä¿¡æ¯å¯ä»¥çœ‹åˆ°è®­ç»ƒåæ¨¡å‹æƒé‡ä¿å­˜åœ¨`runs\train\exp4\weights`ï¼Œå½“ç„¶è¿™ä¸æ˜¯å›ºå®šçš„ï¼Œè¦ä»¥è¾“å‡ºä¸ºå‡†ã€‚

**éªŒè¯æ¨¡å‹**

Validation Settingsï¼šhttps://docs.ultralytics.com/usage/cfg/#validation-settings

```python
def val():
    os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
    model = YOLO("runs/train/exp4/weights/best.pt")
    results = model.val(data='./simd.yaml', split='val', batch=1, project='runs/val', name='exp', half=False)
```

```bash
Ultralytics 8.3.89 ğŸš€ Python-3.11.4 torch-2.6.0+cpu CPU (Intel Core(TM) i7-4790 3.60GHz)
YOLO11n summary (fused): 100 layers, 2,585,077 parameters, 0 gradients, 6.3 GFLOPs
val: Scanning D:\dev\php\magook\trunk\server\learn-yolo\datasets\simd\labels\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]

                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.73it/s]
                   all         20        146      0.823    0.00714     0.0486     0.0289
                   car          7         50          1          0          0          0
                 Truck          5         16          1          0          0          0
                   Van          9         23          1          0          0          0
          Long Vehicle          1          7          1          0    0.00252   0.000757
                   Bus          3          5          1          0    0.00539   0.000539
              Airliner         14         14      0.231     0.0714      0.392      0.243
      Trainer Aircraft          2         11          1          0     0.0862     0.0452
                Others          5         10          1          0          0          0
           Stair Truck          5          6          0          0          0          0
        Pushback Truck          3          4          1          0          0          0
Speed: 2.8ms preprocess, 144.3ms inference, 0.0ms loss, 5.9ms postprocess per image
Results saved to runs\val\exp
```



**æ¨¡å‹é¢„æµ‹**

```python
def predict2():
    model = YOLO("runs/train/exp4/weights/best.pt")
    results = model(["datasets/simd/images/train/0011.jpg"])

    for k, result in enumerate(results):
        filename = util.generate_random_string(15)
        result.save(filename="imgs_result/"+filename+".jpg")
```

```bash
0: 480x640 (no detections), 133.2ms
Speed: 6.1ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)
```

ä½†æ˜¯å®ƒå¹¶æ²¡æœ‰æ£€æµ‹åˆ°å¯¹è±¡ã€‚ã€‚ã€‚

äºæ˜¯å°† train çš„ epochs æ”¹æˆ 100ï¼Œé‡æ–°è®­ç»ƒã€‚è¿™æ¬¡å®ƒèƒ½è¯†åˆ«åˆ°äº†ã€‚

```bash
0: 480x640 2 Airliners, 134.8ms
Speed: 5.4ms preprocess, 134.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)
```

![image-20250319113839719](D:\dev\php\magook\trunk\server\md\img\image-20250319113839719.png)



é‚£ä¸ºä»€ä¹ˆ epochs å‚æ•°èƒ½å½±å“æ¨¡å‹çš„æ•ˆæœå‘¢ï¼Œå®ƒä»£è¡¨è®­ç»ƒå¤šå°‘è½®ï¼Œè¿™å°±æ˜¯ä¸€ä¸ªâ€œç†Ÿèƒ½ç”Ÿå·§â€çš„è¿‡ç¨‹ï¼Œè·Ÿäººç±»çš„å­¦ä¹ è¿‡ç¨‹æ˜¯ä¸€æ ·çš„ï¼Œä¸€æœ¬ä¹¦ä½ çœ‹ä¸€ç™¾éæ€»æ¯”çœ‹åéè¦ç†è§£çš„é€å½»ä¸€äº›ã€‚

ä»¥ä¸‹æ˜¯é€šä¹‰åƒé—®çš„å›ç­”ï¼š

`epochs`å‚æ•°åœ¨è®­ç»ƒæ¨¡å‹æ—¶ä»£è¡¨æ•´ä¸ªè®­ç»ƒé›†å°†è¢«éå†çš„æ¬¡æ•°ã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœä½ è®¾ç½®`epochs=10`ï¼Œé‚£ä¹ˆè®­ç»ƒé›†ä¸­çš„æ¯ä¸ªæ ·æœ¬éƒ½ä¼šè¢«ç½‘ç»œçœ‹è¿‡10æ¬¡ã€‚è¿™ä¸ªå‚æ•°å¯¹æ¨¡å‹çš„æ•ˆæœæœ‰ç€ç›´æ¥çš„å½±å“ï¼Œä¸»è¦åŸå› å¦‚ä¸‹ï¼š

1. **å­¦ä¹ æœºä¼šå¢åŠ **ï¼šéšç€epochæ•°é‡çš„å¢åŠ ï¼Œæ¨¡å‹æœ‰æ›´å¤šæœºä¼šå»å­¦ä¹ æ•°æ®é›†ä¸­çš„æ¨¡å¼å’Œç‰¹å¾ã€‚ç†è®ºä¸Šï¼Œæ›´å¤šçš„epochå¯ä»¥è®©æ¨¡å‹æ›´å¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚
2. **è¯¯å·®å‡å°‘**ï¼šåœ¨ä¸€ä¸ªepochè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹é€šè¿‡åå‘ä¼ æ’­ç®—æ³•è°ƒæ•´å…¶æƒé‡ä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼ˆå³é¢„æµ‹å€¼ä¸å®é™…å€¼ä¹‹é—´çš„å·®å¼‚ï¼‰ã€‚å› æ­¤ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼Œéšç€epochæ•°é‡çš„å¢åŠ ï¼Œæ¨¡å‹çš„æ€»ä½“è¯¯å·®ä¼šé€æ¸å‡å°‘ã€‚
3. **è¿‡æ‹Ÿåˆé£é™©**ï¼šç„¶è€Œï¼Œè¿™å¹¶ä¸æ„å‘³ç€epochè¶Šå¤šè¶Šå¥½ã€‚å¦‚æœepochæ•°é‡è¿‡å¤šï¼Œæ¨¡å‹å¯èƒ½ä¼šå¼€å§‹è®°ä½è®­ç»ƒæ•°æ®çš„å…·ä½“ç»†èŠ‚ï¼Œè€Œä¸æ˜¯å­¦ä¹ é€šç”¨çš„æ¨¡å¼æ¥åšå‡ºé¢„æµ‹ã€‚è¿™ç§ç°è±¡ç§°ä¸ºè¿‡æ‹Ÿåˆï¼Œå®ƒä¼šå¯¼è‡´æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ã€‚
4. **æ”¶æ•›æ€§**ï¼šå¯¹äºæŸäº›æ¨¡å‹è€Œè¨€ï¼Œç»è¿‡ä¸€å®šæ•°é‡çš„epochåï¼Œæ€§èƒ½æå‡ä¼šå˜å¾—å¾®ä¹å…¶å¾®ï¼Œå› ä¸ºæ¨¡å‹å·²ç»æ¥è¿‘æœ€ä¼˜è§£ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç»§ç»­å¢åŠ epochæ•°é‡å¯èƒ½ä¸ä¼šå¸¦æ¥æ˜¾è‘—çš„å¥½å¤„ã€‚
5. **è®¡ç®—æˆæœ¬**ï¼šæ›´å¤šçš„epochä¹Ÿæ„å‘³ç€æ›´é«˜çš„è®¡ç®—æˆæœ¬ã€‚å› æ­¤ï¼Œåœ¨å®è·µä¸­ï¼Œéœ€è¦æ‰¾åˆ°ä¸€ä¸ªå¹³è¡¡ç‚¹ï¼Œæ—¢èƒ½ä½¿æ¨¡å‹è¾¾åˆ°æ»¡æ„çš„æ€§èƒ½æ°´å¹³ï¼Œåˆä¸ä¼šå¯¼è‡´è¿‡é«˜çš„è®¡ç®—å¼€é”€ã€‚



**æ¨¡å‹å¯¼å‡º**

å°† pt æ¨¡å‹å¯¼å‡ºä¸ºå…¶ä»–æ ¼å¼çš„ã€‚

æ”¯æŒçš„æ ¼å¼ï¼šhttps://docs.ultralytics.com/tasks/detect/#export



**é˜…è¯»**

[YOLOç³»åˆ—å‘å±•å†ç¨‹ï¼šä»YOLOv1åˆ°YOLO11ï¼Œç›®æ ‡æ£€æµ‹æŠ€æœ¯çš„é©æ–°ä¸çªç ´](https://mp.weixin.qq.com/s/Fol-Y_C46Yervorfx07z5Q)

[YOLO11è¯¦è§£](https://mp.weixin.qq.com/s/iTwprX2crSc13Sahtsfa_g)

[YOLOæ¨¡å‹ç»¼è¿°ï¼šYOLO11åŠå…¶å‰èº«çš„å…¨é¢åŸºå‡†ç ”ç©¶](https://mp.weixin.qq.com/s/QFomq1oM2Smgm8OY9DaaRQ)



